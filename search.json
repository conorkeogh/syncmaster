[
  {
    "objectID": "events.html",
    "href": "events.html",
    "title": "Analysis",
    "section": "",
    "text": "After recording data, event signals are present as pulses of varying duration on a single channel.\nHowever, in order to be able to analyse the recorded signals synchronised to the events, it is necessary to recover the exact timings of the onsets of each discrete event type."
  },
  {
    "objectID": "events.html#loading-data",
    "href": "events.html#loading-data",
    "title": "Analysis",
    "section": "Loading data",
    "text": "Loading data\nData should be loaded as necessary following recording. The event synchronisation channel recording should be part of this data.\nHere is a simple example loading oscilloscope data recorded from the output of the device while each event type is triggered in turn.\n\n# Load example data - recorded signals using oscilloscope\ndata = np.loadtxt('./example_data/all_triggers.csv', delimiter=',', skiprows=2, usecols=[0,1])\nsamplerate = 250 # Hz\n\n# Split data into time and voltage\nt = data[:, 0]\nv = data[:, 1]\n\nIn this example, the sample data is recorded at 250Hz and saved as a CSV file with a two-line header and two columns. The first column is the time, the second is the recorded voltage, i.e. the event signal data.\nThis sample data is visualised below."
  },
  {
    "objectID": "events.html#recovering-event-timings",
    "href": "events.html#recovering-event-timings",
    "title": "Analysis",
    "section": "Recovering event timings",
    "text": "Recovering event timings\nIn order to synchronise the recorded signals to the behavioural events, we need to recover the exact timings of each discrete event type.\nThe package includes a function that allows us to determine exact event timings for each event type from the single-channel data of variable duration pulses.\n\nsource\n\ngetEvents\n\n getEvents (data:numpy.ndarray, samplerate:int, eventIDs:list=None)\n\nRecover discrete event timings from single-channel data\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\nSingle-channel data; 1 x t array\n\n\nsamplerate\nint\n\nRecording sample rate (Hz)\n\n\neventIDs\nlist\nNone\nList of unique event IDs\n\n\nReturns\nndarray\n\nEvent timings; n x t array\n\n\n\nThe input data is provided as a one-dimensional numpy.ndarray. This corresponds to the recorded output signal at every timepoint.\nThe samplerate parameter is the sample rate of the recording system in Hz. This allows the expected duration of pulses in time to be linked to the expected number of samples in a given pulse.\nThe eventIDs parameter allows user-defined events to be recovered from the data. This is not necessary if using the simple, pre-defined events (start, end, event1 and event2). Using this option is described in further detail below.\n\n# Recover event data\nevents = getEvents(v, samplerate)\n\nThis function returns a two-dimensional numpy.ndarray. Each row corresponds to an event type in the order start, end, event1, event2. Each column corresponds to a single timepoint in the original recording.\nThe recovered event signals will be 0 everywhere except for at the timepoints where that event type occured, where they will be 1.\nIn this way, we recover the precise event onset times for each individual event type from the single-channel variable duration pulse data.\nThe event data can then be plotted to verify that we have recovered the exact event timings.\n\n# Plot results\nfig, ax = plt.subplots(5, 1, sharex='row', figsize=(10,6))\n\nax[0].plot(t, v)\nax[1].plot(t, events[0,:])\nax[2].plot(t, events[1,:])\nax[3].plot(t, events[2,:])\nax[4].plot(t, events[3,:])\n\n\n\n\n\n# Plot results\nfig, ax = plt.subplots(5, 1, sharex='row', figsize=(10,6))\n\nax[0].plot(t, v)\nax[1].plot(t, events[0,:])\nax[2].plot(t, events[1,:])\nax[3].plot(t, events[2,:])\nax[4].plot(t, events[3,:])"
  },
  {
    "objectID": "events.html#user-defined-events",
    "href": "events.html#user-defined-events",
    "title": "Analysis",
    "section": "User-defined events",
    "text": "User-defined events\nIf using user-defined events, event timing can be recovered by passing a list of unique event IDs to the optional eventIDs parameter of getEvents().\n\n# Define event IDs\nEND = 1\nEVENT1 = 2\nEVENT2 = 3\nCONDITION1 = 4\nCONDITION2 = 5\n\n# Create list of event IDs\neventIDs = [END, EVENT1, EVENT2, CONDITION1, CONDITION2]\n\nThe getEvents() function can then be used as before, now taking the event IDs as an input.\n\n# Recover event data using user-defined event IDs\nevents = getEvents(v, samplerate, eventIDs=eventIDs)\n\nThis function returns a two-dimensional numpy.ndarray. Each row corresponds to an event type. The order of events is defined by the ordering in the input eventIDs list, i.e. the ith row of the events array corresponds to occurences of the ith event in eventIDs list.\nIn this example, the events array will contain five rows in the order END, EVENT1, EVENT2, CONDITION1, CONDITION2."
  },
  {
    "objectID": "events.html#data-analysis",
    "href": "events.html#data-analysis",
    "title": "Analysis",
    "section": "Data analysis",
    "text": "Data analysis\nThis produces an array with 1 at the onset of each event type.\nThis allows for recorded signals to be easily extracted around these event signals, allowing windowing, averaging, etc.\nBy recovering and separating discrete event types, this allows for multiple different discrete event types to be encoded using a single input channel on the recording system.\nThis provides a straightforward system for performing synchronisation of recorded signals to complex behavioural tasks with arbitrary events.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "initialisation.html",
    "href": "initialisation.html",
    "title": "Initialisation",
    "section": "",
    "text": "The software drivers provide a simple interface to communicate with the device in order to send event signals from behavioural tasks to synchronise with recorded data."
  },
  {
    "objectID": "initialisation.html#importing-the-drivers",
    "href": "initialisation.html#importing-the-drivers",
    "title": "Initialisation",
    "section": "Importing the drivers",
    "text": "Importing the drivers\nOnce installed, the drivers can be imported into the task script like any package.\n\n# Import driver package\nimport syncmaster\n\nAll contents of the driver package can then be accessed using the prefix syncmaster., i.e. the SyncMaster object is accessed using syncmaster.SyncMaster().\nAlternatively, all contents of the package can be imported directly into the present script’s namespace:\n\n# Import all package contents into current namespace\nfrom syncmaster import *\n\nPackage contents can then be accessed using their names directly without the need for a prefix, i.e. SyncMaster().\nWhile slightly more convenient, this runs the risk of colliding with function and object names imported from other packages, so we recommend using the package prefix where possible."
  },
  {
    "objectID": "initialisation.html#creating-the-device-object",
    "href": "initialisation.html#creating-the-device-object",
    "title": "Initialisation",
    "section": "Creating the device object",
    "text": "Creating the device object\nThe software communicates with the device hardware using a software object. All device commands are controlled using this object.\n\nsource\n\nSyncMaster\n\n SyncMaster ()\n\nDevice object for controlling synchronisation\nIn order to use the device in a task script, we must first create the device object. This should be done once at the beginning of the script.\n\n# Create device object\ndevice = syncmaster.SyncMaster()\n\nThis automatically carries out all initialisation procedures, including locating the device on the host system and ensuring the device is communicating correctly.\nNote that an error will be produced on attempting to create the device object if the device is not connected to the host system.\nOnce the device has been initialised once in this way, it is ready to send event signals to the recording system as outlined in the triggering section."
  },
  {
    "objectID": "initialisation.html#shutting-down-the-device",
    "href": "initialisation.html#shutting-down-the-device",
    "title": "Initialisation",
    "section": "Shutting down the device",
    "text": "Shutting down the device\nOn completing the task, the communicating channel between the host system and the device should be shut down.\n\nsource\n\nSyncMaster.close\n\n SyncMaster.close ()\n\nCloses device connection\nThe device should be shut down using the close command at the end of the task.\n\n# Close device\ndevice.close()\n\nIt can then be disconnected from the host system.\nThis ensures that all communications ports are closed correctly to avoid any errors.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "The SyncMaster system was developed by the Oxford Neural Interfacing group for use in neuroscience research. Please contact us with any questions or to report any issues with the system."
  },
  {
    "objectID": "contact.html#oxford-neural-interfacing",
    "href": "contact.html#oxford-neural-interfacing",
    "title": "Contact",
    "section": "Oxford Neural Interfacing",
    "text": "Oxford Neural Interfacing\nFurther information on the Oxford Neural interfacing group, our work and contact details can be found on the group website."
  },
  {
    "objectID": "contact.html#github",
    "href": "contact.html#github",
    "title": "Contact",
    "section": "GitHub",
    "text": "GitHub\nInformation on the SyncMaster device can be found on the project’s GitHub respository.\nIssues can be reported via GitHub here or via the “Report an issue” link in the sidebar."
  },
  {
    "objectID": "contact.html#email",
    "href": "contact.html#email",
    "title": "Contact",
    "section": "Email",
    "text": "Email\nAny further questions or issues related to the device can be directed to Conor Keogh: conor.keogh@nds.ox.ac.uk.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "triggering.html",
    "href": "triggering.html",
    "title": "Triggering",
    "section": "",
    "text": "After initialising the device, event signals can be sent via the output port. These are then recorded by the recording system. By using event signals of differing lengths, multiple different event signals can be sent over a single output channel.\nEvents can be specified using simple, pre-specified events or more flexibility can be added by defining user-specified events."
  },
  {
    "objectID": "triggering.html#event-types",
    "href": "triggering.html#event-types",
    "title": "Triggering",
    "section": "Event types",
    "text": "Event types\nHere, we implement four event types: a start signal to indicate the start of a trial, an end signal to indicate the end of a trial and event1 and event2 signals to indicate two event types during trials.\nEach signal type has a different duration:\n\n\n\nEvent type\nDuration (ms)\n\n\n\n\nStart\n50\n\n\nEnd\n100\n\n\nEvent 1\n150\n\n\nEvent 2\n200\n\n\n\nEach signal type is generated using simple commands from within the task script. Recovering the discrete event timings is discussed in the analysis section.\n\nStart signal\nThe start signal is intended to indicate the beginning of a new trial. It is produced by using the SyncMaster object.\n\nsource\n\n\nSyncMaster.start\n\n SyncMaster.start ()\n\nSend start signal\nIncorporating this into the task script sends a 50ms pulse over the output channel every time this command is executed.\n\n# Send start signal\ndevice.start()\n\nAn example output for a start signal recorded with an oscilloscope is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nEnd signal\nThe end signal is intended to indicate the end of a trial. It is produced by using the SyncMaster object.\n\nsource\n\n\nSyncMaster.end\n\n SyncMaster.end ()\n\nSend end signal\nIncorporating this into the task script sends a 100ms pulse over the output channel every time this command is executed.\n\n# Send end signal\ndevice.end()\n\nAn example output for a end signal recorded with an oscilloscope is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nEvent 1 signal\nThe event1 signal is intended to indicate the occurence of an arbitrary event within a trial. It is produced by using the SyncMaster object.\n\nsource\n\n\nSyncMaster.event1\n\n SyncMaster.event1 ()\n\nSend event 1 signal\nIncorporating this into the task script sends a 150ms pulse over the output channel every time this command is executed.\n\n# Send event 1 signal\ndevice.event1()\n\nAn example output for a event1 signal recorded with an oscilloscope is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nEvent 2 signal\nThe event2 signal is intended to indicate the occurence of an arbitrary event within a trial. This allows for two different arbitrary events to be encoded in addition to start and end signals. It is produced by using the SyncMaster object.\n\nsource\n\n\nSyncMaster.event2\n\n SyncMaster.event2 ()\n\nSend event 2 signal\nIncorporating this into the task script sends a 200ms pulse over the output channel every time this command is executed.\n\n# Send event 2 signal\ndevice.event2()\n\nAn example output for a event2 signal recorded with an oscilloscope is shown below."
  },
  {
    "objectID": "triggering.html#user-specified-events",
    "href": "triggering.html#user-specified-events",
    "title": "Triggering",
    "section": "User-specified events",
    "text": "User-specified events\nFor complex task designs, simple triggers such as start, end and two unique event markers may not be sufficient.\nFor these cases, user-defined event IDs can be defined. Triggers can then be sent via the device to identify each of these events on the output channel.\n\n# Define event IDs\nEND = 1\nEVENT1 = 2\nEVENT2 = 3\nCONDITION1 = 4\nCONDITION2 = 5\n\nEach event ID is assigned a single unique identifier.\n\nsource\n\nSyncMaster.event\n\n SyncMaster.event (eventID)\n\nCreate event marker\nThe event command allows for triggers corresponding to user-defined event IDs to be sent. Each event type should have a single, unique ID, defined as an integer. Up to 100 unique event types can be defined using this approach. This offers great flexibility regarding marking multiple conditions and events in complex task designs.\n\n''' Run simple trial using user-specified events '''\n# Start trial with specified condition\ndevice.event(CONDITION1) \n\n''' Run behavioural task '''\n\n# Trigger specific event\ndevice.event(EVENT1)\n\n''' Continue behavioural task '''\n\n# Send end trigger\ndevice.event(END)\n\nThis approach offers significantly more flexibility than using the simple, pre-defined event triggers.\nThis comes at the cost of requiring event IDs to be carefully tracked to ensure that all events have unique IDs.\nFurther, the trigger duration for each trial type is ten times the event ID, measured in milliseconds (i.e. the trigger for event 3 is 30ms in length). As a consequence, events with high event IDs result in relatively longer triggers. This should be kept in mind for situations where multiple triggers occur in rapid succession. For this reason, a limit of 100 event types is in place to limit the maximum trigger duration to one second.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "In order to synchronise recorded signals and behavioural tasks, the device needs to be connected to the computer running the behavioural task and to one of the input channels of the system recording the signals of interest."
  },
  {
    "objectID": "setup.html#connecting-to-computer",
    "href": "setup.html#connecting-to-computer",
    "title": "Setup",
    "section": "Connecting to computer",
    "text": "Connecting to computer\nThe device should be connected to the computer using a standard USB cable.\nThe host computer operating system will enumerate the device as a COM port. This can be ignored; the device drivers will use this port to communicate with the device to send signals."
  },
  {
    "objectID": "setup.html#connecting-to-recording-system",
    "href": "setup.html#connecting-to-recording-system",
    "title": "Setup",
    "section": "Connecting to recording system",
    "text": "Connecting to recording system\nThe device should be connected to an input channel on the recording system.\nThe device provides a standard BNC output. This can be connected to the input of recording device.\nNote that the input ports of the recording device must be able to tolerate a 5V input as this is the voltage of the signal pulses used."
  },
  {
    "objectID": "setup.html#verifying-connection",
    "href": "setup.html#verifying-connection",
    "title": "Setup",
    "section": "Verifying connection",
    "text": "Verifying connection\nOnce connected, a test signal can be sent to verify that the systems are communicating correctly.\nBy sending a predictable signal through the device, we can verify that the correct signals are being generated and that the recording system is receiving these correctly.\nA simple routine to implement this included in the device drivers.\n\nsource\n\nSyncMaster.testSignal\n\n SyncMaster.testSignal ()\n\nSends test pulses over output port once per second for five seconds\nThis can be used in a simple script to set up the device and verify that all systems are communicating effectively in order to allow synchronisation.\n\n# Import library\nimport syncmaster\n\n# Create device object\ndevice = syncmaster.SyncMaster()\n\n# Send test signal\ndevice.testSignal()\n\nThis will generate a trigger on the output port once every second for five seconds. If this is visible on the recording system, the system is connected and functioning correctly.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation",
    "section": "",
    "text": "The device is controlled using Python drivers. Once installed, these can be integrated into the behavioural task script to send commands to the device in order to record event signals for synchronisation."
  },
  {
    "objectID": "install.html#install-using-pip",
    "href": "install.html#install-using-pip",
    "title": "Installation",
    "section": "Install using pip",
    "text": "Install using pip\nThe simplest way to install the device drivers is using the pip package manager.\npip install syncmaster\nThis will automatically install the drivers and all required dependencies. These can then simply be imported into the task script in order to use the device."
  },
  {
    "objectID": "install.html#install-from-source",
    "href": "install.html#install-from-source",
    "title": "Installation",
    "section": "Install from source",
    "text": "Install from source\nThe driver source code can be downloaded directly by cloning the package repository.\ngit clone https://github.com/conorkeogh/syncmaster.git\nThe package source code is located in the syncmaster subdirectory. This can then be installed localled using your package manager. The package files can also be used directly by placing these in the task source directory and importing them."
  },
  {
    "objectID": "install.html#checking-package-version",
    "href": "install.html#checking-package-version",
    "title": "Installation",
    "section": "Checking package version",
    "text": "Checking package version\nThe version of the drivers installed on the system can be checked in Python by importing the package.\n\n# Import package\nimport syncmaster\n\n# Check version number\nsyncmaster.__version__\n\nWe recommend using the latest version in order to avoid any issues with older versions of the drivers.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SyncMaster",
    "section": "",
    "text": "The SyncMaster provides a simple way to synchronise behavioural tasks with recorded signals.\nThe device is connected to the computer running the task via USB and the output port is connected to an input on the recording system. The task script can then send commands to the device, producing event-specific signals on the output channel which can be used to time-lock recorded signals to behavioural events."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "SyncMaster",
    "section": "Installation",
    "text": "Installation\nThe drivers to run the device using Python can be installed using pip:\npip install syncmaster\nFurther details are given in the installation section.\nOnce the Python package is installed and the device connected as outlined in the setup section, the device can be initialised and triggered to synchronise behavioural events with recorded signals. A simple application is shown below, with further details available in the initialisation and triggering sections."
  },
  {
    "objectID": "index.html#example-application",
    "href": "index.html#example-application",
    "title": "SyncMaster",
    "section": "Example application",
    "text": "Example application\nAfter importing the library, the device must be initialised. This should be done once at the beginning of the behavioural task.\nTriggers can then be sent using simple commands. These can be integrated with the behavioural task in order to indicate the occurence of events of interest. This generates signals on the output channel which are recorded and can be used to analyse recorded data relative to behavioural events.\n\n# Import library\nimport syncmaster\n\n# Create device object\ndevice = syncmaster.SyncMaster()\n\n# Run trial with start and end signals\ndevice.start()    # Send start signal\n\n''' Run behavioural task '''\n\ndevice.end()      # Send end signal\n\n# Close communication channel when finished\ndevice.close()\n\nOn completion of the task, the communication channel with the device should be formally closed.\nNote that more complex task designs with up to 100 user-defined event types can be accommodated. This is outlined in detail in the triggering section."
  },
  {
    "objectID": "index.html#output",
    "href": "index.html#output",
    "title": "SyncMaster",
    "section": "Output",
    "text": "Output\nThe device produced pulses of differing lengths on a single output channel. Each pulse length corresponds to a specific event type.\nThe package includes a function for recovering the discrete event timings from this single-channel pulse data in order to facilitate data analysis. A simple example is shown below with raw recorded data above and each subsequent row showing recovered trigger timings for each event type. This is described in further detail in the analysis section.\n\n\n\n\n\n\n\n\n\n\nThis approach can also be used to recover precise event timings for user-defined events. This is outlined in detail in the analysis section.\n\n\n\n\nOxford Neural Interfacing 2023\n\n\n\n\n\n\n\nOxford Neural Interfacing 2023"
  }
]